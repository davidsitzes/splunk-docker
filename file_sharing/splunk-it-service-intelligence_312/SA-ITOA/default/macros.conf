# Copyright (C) 2005-2018 Splunk Inc. All Rights Reserved.

###############################################
# ITOA Alert Search Macros
###############################################
# Used to convert raw data into the service aggregate (no entity breakdown)
[aggregate_raw_into_service(2)]
args = aggregate_statop, threshold_field
definition = stats $aggregate_statop$($threshold_field$) AS alert_value | eval is_service_aggregate="1", is_entity_defined="0", entity_key="service_aggregate", entity_title="service_aggregate" | `gettime`

# Used to convert raw data into the per entity alert_values
[aggregate_raw_into_entity(3)]
args = entity_statop, threshold_field, entity_field
definition = stats $entity_statop$($threshold_field$) AS alert_value by $entity_field$ | `gettime`

# Used to check if object is in maintenance
[is_object_in_maintenance(2)]
args = object_type, object_key_field
definition = eval maintenance_object_type = "$object_type$", maintenance_object_key = $object_key_field$ | lookup operative_maintenance_log maintenance_object_type, maintenance_object_key OUTPUT _key as maintenance_log_key | eval in_maintenance = if(IsNull(maintenance_log_key), 0, 1) | fields - maintenance_object_key, maintenance_object_type, maintenance_log_key

# process searched entities, primarily for internal use only
# assumes lookup itsi_entities was invoked prior to this macro
[normalize_matched_entities(1)]
args = entity_field
definition = `is_object_in_maintenance("entity", entity_key)` | eval is_entity_defined=if(isnull(entity_key), "0", "1"), entity_key=if(isnull(entity_key), "N/A", entity_key), entity_title=coalesce(entity_title,'$entity_field$'), is_service_aggregate="0", is_entity_in_maintenance = in_maintenance | fields - $entity_field$, in_maintenance, entity_sec_grp

# Used to augment search results for entities
[match_entities(1)]
args = entity_field
definition = lookup itsi_entities identifier.values as $entity_field$ OUTPUT title as entity_title, _key as entity_key, services._key as serviceid, sec_grp as entity_sec_grp | `normalize_matched_entities($entity_field$)`

# Used to augment search results for entities by security group that entities belong to
[match_entities(2)]
args = entity_field, sec_grp_field
definition = lookup itsi_entities identifier.values as $entity_field$, sec_grp as $sec_grp_field$ OUTPUT title as entity_title, _key as entity_key, services._key as serviceid, sec_grp as entity_sec_grp | `normalize_matched_entities($entity_field$)`

# Used to augment search results for filter entities by security group that entities belong to
# Specifically, used to add serviceid for each entity result
# Used by shared base search when entity filter and entity breakdown fields are different
[match_filter_entites(2)]
args = entity_filter_field, sec_grp_field
definition = lookup itsi_entities identifier.values as $entity_filter_field$, sec_grp as sec_grp OUTPUT services._key as serviceid

# Used to augment search results for breakdown entities by security group that entities belong to
# Used by shared base search when entity filter and entity breakdown fields are different
[match_breakdown_entities(2)]
args = entity_breakdown_field, sec_grp_field
definition = lookup itsi_entities identifier.values as $entity_breakdown_field$, sec_grp as $sec_grp_field$ OUTPUT title as entity_title, _key as entity_key, sec_grp as entity_sec_grp | `normalize_matched_entities($entity_breakdown_field$)`

# Used to filter out entities when they are in maintenance
# Primarily consumed by notable events to filter out correlation search events that have maintenance entities associated
# This macro assumes that match_entities macro was used earlier which populated is_entity_in_maintenance field
[filter_maintenance_entities]
args =
definition = where IsNull(is_entity_in_maintenance) OR (is_entity_in_maintenance != 1)

# Given a bunch of service ids filter out events that have all the services in maintenance
# This is primarily used by notable events to not generate events when services associated with a correlation search
# are all in maintenance
[filter_maintenance_services(1)]
args = service_ids
definition = eval service_ids = "$service_ids$" | makemv delim="," service_ids | mvexpand service_ids | `is_object_in_maintenance("service", service_ids)` | where IsNull(in_maintenance) OR (in_maintenance != 1) | fields - in_maintenance | mvcombine service_ids | fields - service_ids

# Used to create an aggregate event from the entity breakdown events
[aggregate_entity_into_service(1)]
args = service_statop
definition = appendpipe [stats $service_statop$(alert_value) AS alert_value by serviceid, is_entity_in_maintenance | sort 0 serviceid is_entity_in_maintenance | dedup consecutive=t serviceid | eval  is_all_entities_in_maintenance=is_entity_in_maintenance, is_service_aggregate="1", is_entity_defined="0", entity_key="service_aggregate", entity_title="service_aggregate"] | `gettime`

#Used to assess the severity for any KPI base search
[assess_severity(1)]
args = kpibasesearch
definition = setseverityfields kpibasesearch="$kpibasesearch$" | fields - is_all_entities_in_maintenance, entity_keys

# Used to assess severity for any KPI alert search
[assess_severity(2)]
args = serviceid, kpiid
definition = eval maintenance_service_id = "$serviceid$" | `is_object_in_maintenance("service", maintenance_service_id)` | eval is_service_in_maintenance = in_maintenance | fields - in_maintenance, maintenance_service_id | setseverityfields serviceid="$serviceid$", kpiid="$kpiid$" | fields - is_all_entities_in_maintenance

# Used to assess severity for any KPI alert search with no data and max severity event
# Note:
# - If no event passed to search command then is generate no data event which may not suitable for certain case like previewing charts
# - It also generate a max severity event which is used by health compute search
# is_handle_no_data and is_gen_max_severity_event is boolean flags
[assess_severity(4)]
args = serviceid, kpiid, is_handle_no_data, is_gen_max_severity_event
definition = eval maintenance_service_id = "$serviceid$" | `is_object_in_maintenance("service", maintenance_service_id)` | eval is_service_in_maintenance = in_maintenance | fields - in_maintenance, maintenance_service_id | setseverityfields serviceid="$serviceid$", kpiid="$kpiid$" handle_no_data=$is_handle_no_data$ generate_max_severity_event=$is_gen_max_severity_event$ | fields - is_all_entities_in_maintenance

[assess_urgency]
definition = eval urgency = if (is_service_in_maintenance == 1, 0, urgency)

###############################################
# ITOA Backfill Search Macros
###############################################
# Used to convert raw data into per entity alert_values over backfill buckets
# Functionally this should produce similar results to `aggregate_raw_into_entity_time_series`
# but with possibly overlapping buckets.
# This macro assumes that events have been tagged with appropriate bucket IDs given by
# the values of (possibly multivalued) $bucket_field$.
# - the _time of each bucket is the time of its "latest" end
# - buckets are "snapped" to monitoring frequency-spaced time intervals
# - due to the fact that buckets overlap, the "latest" end will be common for all overlapping
#   buckets at the end of the search time range, necessitating stats first(*) by _time
# - bucket_field string stats with -1 for times corresponding to bucket gaps; these will be dropped
[aggregate_raw_into_entity_backfill(5)]
args = entity_statop, threshold_field, entity_field, alert_period, bucket_field
definition = stats max(_time) AS maxtime, $entity_statop$($threshold_field$) AS alert_value BY $bucket_field$, $entity_field$ | eval _time=maxtime+$alert_period$*60 |  bucket _time span=$alert_period$m | stats first(*) as * by _time, $entity_field$ | eval _drop=substr($bucket_field$, 0, 2) | search _drop!=-1 | fields - $bucket_field$, maxtime

[aggregate_raw_into_service_backfill(4)]
args = service_statop, threshold_field, alert_period, bucket_field
definition = stats max(_time) AS maxtime, $service_statop$($threshold_field$) AS alert_value BY $bucket_field$ | eval _time=maxtime+$alert_period$*60 |  bucket _time span=$alert_period$m | stats first(*) as * by _time | eval _drop=substr($bucket_field$, 0, 2) | search _drop!=-1 | fields - $bucket_field$, maxtime  | eval is_service_aggregate="1", is_entity_defined="0", entity_key="service_aggregate", entity_title="service_aggregate"

[aggregate_entity_into_service_backfill(1)]
args = service_statop
definition = appendpipe [stats $service_statop$(alert_value) AS alert_value, count(entity_key) AS entities_count, count(eval(is_entity_in_maintenance=1)) AS maintenance_entities_count by _time | eval is_service_aggregate="1", is_entity_defined="0", entity_key="service_aggregate", entity_title="service_aggregate", is_all_entities_in_maintenance=if ((entities_count == maintenance_entities_count) AND (entities_count > 0), 1, 0) | fields - entities_count maintenance_entities_count]



###############################################
# ITOA Time Series Search Macros
###############################################
# Used to convert raw data into the per entity alert_values over bucketed time (note this is not the same as timechart output)
[aggregate_raw_into_entity_time_series(4)]
args = entity_statop, threshold_field, entity_field, search_alert_earliest
definition = bucket _time span=$search_alert_earliest$m | stats $entity_statop$($threshold_field$) AS alert_value by _time, $entity_field$

# Used to convert raw data into a timechart format of a limited set of entities
[aggregate_raw_into_limited_entity_time_series(4)]
args = entity_statop, threshold_field, entity_field, search_alert_earliest
definition = bucket _time span=$search_alert_earliest$m | stats $entity_statop$($threshold_field$) AS alert_value by _time, $entity_field$ | timechart bins=500 minspan=$search_alert_earliest$m avg(alert_value) AS alert_value by $entity_field$

# Used to aggregate all entity time series data points into a single service time series (in timechart output format)
[aggregate_entity_into_service_time_series(2)]
args = service_statop, search_alert_earliest
definition =  stats $service_statop$(alert_value) AS alert_value, count(entity_key) AS entities_count, count(eval(is_entity_in_maintenance=1)) AS maintenance_entities_count by _time | eval is_all_entities_in_maintenance=if ((entities_count == maintenance_entities_count) AND (entities_count > 0), 1, 0) | fields - entities_count maintenance_entities_count | timechart bins=500 minspan=$search_alert_earliest$m avg(alert_value) AS alert_value

# Used to aggregate all entity time series data points into a single service time series (in timechart output format)
[aggregate_entity_into_service_time_series(3)]
args = service_statop, search_alert_earliest, deep_dive_kpi_statsop
definition =  stats $service_statop$(alert_value) AS alert_value, count(entity_key) AS entities_count, count(eval(is_entity_in_maintenance=1)) AS maintenance_entities_count by _time | eval is_all_entities_in_maintenance=if ((entities_count == maintenance_entities_count) AND (entities_count > 0), 1, 0) | fields - entities_count maintenance_entities_count | timechart bins=500 minspan=$search_alert_earliest$m $deep_dive_kpi_statsop$(alert_value) AS alert_value

# Used to convert raw data into the service aggregate time series (in timechart output format)
[aggregate_raw_into_service_time_series(3)]
args = aggregate_statop, threshold_field, search_alert_earliest
definition = bucket _time span=$search_alert_earliest$m | stats $aggregate_statop$($threshold_field$) AS alert_value by _time | timechart bins=500 minspan=$search_alert_earliest$m avg(alert_value) as alert_value

# Used to convert raw data into the service aggregate time series with the custom stats op (in timechart output format)
[aggregate_raw_into_service_time_series(4)]
args = aggregate_statop, threshold_field, search_alert_earliest, deep_dive_kpi_statsop
definition = bucket _time span=$search_alert_earliest$m | stats $aggregate_statop$($threshold_field$) AS alert_value by _time | timechart bins=500 minspan=$search_alert_earliest$m $deep_dive_kpi_statsop$(alert_value) as alert_value

###############################################
# ITOA Compare Search Macros
# cuts off data to just two alert periods worth and performs comparison of two windows of length of the search_alert_earliest
###############################################
# Entity Level compare search distinguished by needing more args, entity_statop and entity_field
[aggregate_raw_and_compare(5)]
args = entity_statop, service_statop, threshold_field, entity_field, search_alert_earliest
definition = `HandleInfoMaxTime` | head _time>(info_max_time - $search_alert_earliest$*120) | eval alert_value_window=if(_time<(info_max_time-$search_alert_earliest$*60),"last_window", "current_window") | stats $entity_statop$($threshold_field$) AS alert_value by alert_value_window, $entity_field$ | stats $service_statop$(alert_value) AS alert_value by alert_value_window | reverse | delta alert_value AS window_delta | search alert_value_window="current_window" | eval window_direction=if(window_delta >0, "increase", if(window_delta < 0, "decrease", "none")) | `gettime`

# Service Level compare search distinguished by only needing 3 args
[aggregate_raw_and_compare(3)]
args = service_statop, threshold_field, search_alert_earliest
definition = `HandleInfoMaxTime` | head _time>(info_max_time - $search_alert_earliest$*120) | eval alert_value_window=if(_time<(info_max_time-$search_alert_earliest$*60),"last_window", "current_window") | stats $service_statop$($threshold_field$) AS alert_value by alert_value_window | reverse | delta alert_value AS window_delta | search alert_value_window="current_window" | eval window_direction=if(window_delta >0, "increase", if(window_delta < 0, "decrease", "none")) | `gettime`

###############################################
# ITOA Single Value Search Macros
# cuts off data to just one alert period worth and provides a single value
###############################################
# Entity Level compare search distinguished by needing more args, entity_statop and entity_field
[aggregate_raw_into_single_value(5)]
args = entity_statop, service_statop, threshold_field, entity_field, search_alert_earliest
definition = `HandleInfoMaxTime` | head _time>(info_max_time - $search_alert_earliest$*60) | stats $entity_statop$($threshold_field$) AS alert_value by $entity_field$ | stats $service_statop$(alert_value) AS alert_value | `gettime`

# Service Level compare search distinguished by only needing 3 args
[aggregate_raw_into_single_value(3)]
args = service_statop, threshold_field, search_alert_earliest
definition = `HandleInfoMaxTime` | head _time>(info_max_time - $search_alert_earliest$*60) | stats $service_statop$($threshold_field$) AS alert_value | `gettime`

##################################################
# Time related Macros
##################################################
[HandleInfoMaxTime]
args =
definition = addinfo | eval info_max_time=if(info_max_time="+Infinity",now() + 315569260,info_max_time)

[getSearchTimeDiff]
args =
definition = `HandleInfoMaxTime` | eval timeDiff = info_max_time-info_min_time | fields - info_min_time info_max_time info_search_time info_sid

[gettime]
args =
definition = `HandleInfoMaxTime` | eval _time=info_max_time | fields - info_min_time info_max_time info_search_time info_sid

[no_entities_matched]
args =
definition = _time!=*


#####################################################
# Event Management Related macros
#####################################################
[itsi_get_event_id]
args=
definition =  `itsi_map_notable_fields` | `gettime` | `itsi_get_sid_id` | eval event_id= orig_sid."@@notable@@".orig_rid


[itsi_get_sid_id]
args=
definition = addinfo | fields - info_*_time | streamstats count as rid | eval rid=rid-1 | rename info_sid as orig_sid,rid as orig_rid


[itsi_map_notable_fields]
args =
definition = rename _time as orig_time | rename _raw as orig_raw | eval orig_raw=sha256(orig_raw) | `itsi_rename_if_tgt_null(event_id, "orig", "_")` | `itsi_rename_if_tgt_null(tag, "orig", "_")` | rename splunk_server as orig_splunk_server, linecount as orig_linecount, eventtype as orig_eventtype, timestartpos as orig_timestartpos, timeendpos as orig_timeendpos, status as orig_status, owner as orig_owner, owner as orig_owner, tag::* as orig_tag::* | fields - date_*, punct


[itsi_rename_if_tgt_null(3)]
args = field, prefix, sep
definition = eval "$prefix$$sep$$field$"=if(isnull('$prefix$$sep$$field$'), '$field$', '$prefix$$sep$$field$') | fields - "$field$"

# Lookup state (ie. status, severity, owner) for notable events from kv store
[get_notable_event_state]
args =
definition = lookup itsi_notable_event_state_lookup _key AS event_id OUTPUT severity AS lookup_severity, owner AS lookup_owner, status AS lookup_status | eval severity=if(isnull(lookup_severity), severity, lookup_severity), status=if(isnull(lookup_status), status, lookup_status), owner=if(isnull(lookup_owner), owner, lookup_owner) | fields - lookup_*

# spath to extract specific event management fields that we know we need, if a notable event is extremely long
[itsi_extract_notable_event_required_fields]
args =
definition = spath severity | spath status | spath owner | spath title | spath description | spath event_id

# Get notable events with looked up state values
# event_filter - search clause to be run against raw notable event index before state lookup
# Note: to get all results aka no event_filter, call the macro with empty string like this - `itsi_event_management_index_with_state("")`
[itsi_event_management_index_with_state(1)]
args = event_filter
definition = `itsi_event_management_index` $event_filter$ | `itsi_extract_notable_event_required_fields` |`get_notable_event_state`

# Get notable events from splunk index
# Note: use this macro when notable event state values are not needed
[itsi_event_management_index]
args =
definition = index=itsi_tracked_alerts NOT source=itsi@internal@group_closing_event

# Use this when you want to see the group closing events
[itsi_event_management_index_with_close_events]
args =
definition = index=itsi_tracked_alerts

[itsi_event_management_group_index]
args =
definition = index=itsi_grouped_alerts

# Note that if the below macro is updated, it MUST return a field called all_tickets with a structure akin to the eval below
[itsi_event_management_tickets_lookup]
args =
definition = lookup itsi_notable_event_external_ticket event_id OUTPUT tickets.ticket_system AS ticket_system, tickets.ticket_id AS ticket_id, tickets.ticket_url AS ticket_url  | eval all_tickets=mvzip(ticket_system, ticket_id, " - ") | lookup itsi_notable_event_external_ticket event_id AS itsi_group_id OUTPUT tickets.ticket_system AS ticket_system_snow, tickets.ticket_id AS ticket_id_snow, tickets.ticket_url AS ticket_url_snow  | eval all_tickets=if(isnull(all_tickets), mvzip(ticket_system_snow, ticket_id_snow, " - "), mvappend(all_tickets, mvzip(ticket_system_snow, ticket_id_snow, " - "))) | fields - ticket_system, ticket_id, ticket_url, ticket_system_snow, ticket_id_snow, ticket_url_snow

[neap_preview_event_limit]
args =
definition = head 10000

# Take in a string of team_keys in the format of '(sec_grp="itsi_team_key") OR (sec_grp="itsi_team_key")' and returns a filter of service_ids
[itsi_events_compare_teams(1)]
args = itsi_team_id_list
definition = search (service_ids=*null*) OR (NOT service_ids=*) OR [|inputlookup itsi_services_in_team_lookup where $itsi_team_id_list$ | rename _key as service_ids  | eval service_ids="*".service_ids."*" | fields service_ids]

# Take in a string of team_keys in the format of '(sec_grp="itsi_team_key") OR (sec_grp="itsi_team_key")' and returns a filter of itsi_service_ids
[itsi_groups_compare_teams(1)]
args = itsi_team_id_list
definition = search (itsi_service_ids=*null*) OR (NOT itsi_service_ids=*) OR [|inputlookup itsi_services_in_team_lookup where $itsi_team_id_list$ | rename _key as itsi_service_ids  | eval itsi_service_ids="*".itsi_service_ids."*" | fields itsi_service_ids]

#####################################################
# ACE Related macros
#####################################################
[ace_event_limit]
args =
definition = head 10000

##################### moved from itsi #####################

###############################################
# Notable event / MultiKpi Macros
################################################
# Get service name using KV lookup alarm_console_lookup
[get_name_from_kv(2)]
args = input_id_field, output_field
definition = lookup alarm_console_lookup _key AS $input_id_field$ OUTPUT title AS $output_field$

# Get service name from kv using id
[get_service_name(2)]
args = input_id_field, output_field
definition = `get_name_from_kv($input_id_field$, $output_field$)`

# Used to set meta data of correlation search created by KPI Correlation UI
[kpi_correlation_meta_data(1)]
args= timeLabel
definition = eval kpi=coalesce(kpi, "ServiceHealthScore") | `getPercentage(alert_period, occurrence)` | eval service_kpi_ids= itsi_service_id + ":" + itsi_kpi_id | eval statement=kpi." had severity value ".severity." ".occurances." times in "."$timeLabel$" | stats list(statement) as all_info dc(service_kpi_ids) as total_kpis values(*) as * |  eval event_description=mvjoin(all_info, ". ") | eval _raw=event_description

[composite_kpi_meta_data]
args=
definition=  eval gs_search_source="KPI Correlation" | eval time=strftime(_time, " %Y-%m-%d %H:%M:%S.%3N %p") | eval event_description='composite_kpi_name' + " status was " + 'severity_label' + " (Health Score=" + 'health_score' + ") at " + time

# Used in search creation for Multi KPI Alert searches
[getPercentage(2)]
args = period, occurrence
definition = eval alert_period = coalesce($period$, 1) | `getSearchTimeDiff` | eval timeDiffInMin = timeDiff/60 | eval total_occurrences = floor(timeDiffInMin/alert_period) | eval percentage=$occurrence$/total_occurrences*100 | eval percentage=round(percentage, 4) | eval percentage=min(percentage, 100)


###############################################
# KPI Summary Macros
###############################################
# Use this macro to search in itsi_summary index
[get_itsi_summary_index]
args =
definition = index="itsi_summary"

# Use this macro if user want to get partial search for service in itsi_summary index
[get_only_itsi_summary_service(1)]
args = serviceid
definition = indexed_itsi_service_id::$serviceid$

# Use this macro if user want to partial search for kpi in itsi_summary index
[get_only_itsi_summary_kpi(1)]
args = kpiid
definition = indexed_itsi_kpi_id::$kpiid$

# Use this macro if user want to full search for service in itsi_summary index
[get_full_itsi_summary_service(1)]
args = serviceid
definition = `get_itsi_summary_index` indexed_itsi_service_id::$serviceid$

# Use this macro if user want to get full search for kpi in itsi_summary index
[get_full_itsi_summary_kpi(1)]
args = kpiid
definition = `get_itsi_summary_index` indexed_itsi_kpi_id::$kpiid$

# Use to get KPI severity count for one or all possible severity value
[get_kpi_status(1)]
args = severity_name
definition = `get_itsi_summary_index` alert_severity="$severity_name$" `service_level_kpi_only` | stats latest(alert_severity) as alert_severity latest(alert_color) as severity_color by kpiid | stats count as severity_count first(severity_color) as severity_color by alert_severity | rename alert_severity AS severity_name

# Use to get all severity count for defined KPI
[get_all_kpi_status]
args =
definition = `get_kpi_status(*)`

# Use to show the health score of a service over time
[service_health_score_time_series(1)]
args = serviceid
definition = `service_health_data` serviceid="$serviceid$" | timechart avg(health_score) by service

[all_service_health_score_time_series]
definition = `service_health_score_time_series(*)`

[health_score_data]
definition = `get_itsi_summary_index` source=service_health_monitor

[no_health_score_data]
definition = `get_itsi_summary_index` source!=service_health_monitor

[service_level_kpi_only]
definition = ((indexed_is_service_aggregate::1 AND indexed_is_service_max_severity_event::0) OR (source=service_health_monitor AND scoretype="service_health"))

[service_level_kpi_only(1)]
args = max_severity_event
definition = ((indexed_is_service_max_severity_event::$max_severity_event$) OR (source=service_health_monitor AND scoretype="service_health"))

[service_health_data]
definition = `get_itsi_summary_index` source=service_health_monitor scoretype="service_health"

[get_service_health_for_name(1)]
args = service_name
definition = `service_health_data` [ stats count | inputlookup append=t service_kpi_lookup where title="$service_name$" | rename _key as itsi_service_id | fields itsi_service_id count | eventstats count | eval itsi_service_id=if(count<2, "NO SERVICE FOUND",itsi_service_id) | search itsi_service_id=* | table itsi_service_id ]

[composite_health_data]
definition = `get_itsi_summary_index` source=service_health_monitor scoretype="compositekpi_health"

# To pick max severity value event for service
[service_level_max_severity_event_only]
definition = (indexed_is_service_max_severity_event::1 OR (source=service_health_monitor AND scoretype="service_health"))

[entity_level_kpi_only]
definition = indexed_is_service_aggregate::0

[service_level_max_severity_and_service_health_score]
definition = (indexed_is_service_max_severity_event::1 OR (source=service_health_monitor AND scoretype="service_health"))

# Use this to get a list of services and KPIs
# This macro uses inputlookup so use with a pipe for example: | `service_kpi_list`
[service_kpi_list]
definition = inputlookup service_kpi_lookup | rename _key as serviceid title as service_name | eval kpi_info = mvzip('kpis._key', 'kpis.title', "==@@==") | fields kpi_info service_name serviceid | mvexpand kpi_info | rex field=kpi_info "(?<kpiid>.+)==@@==(?<kpi_name>.+)" | fields - kpi_info
########## end of macros moved from itsi #############