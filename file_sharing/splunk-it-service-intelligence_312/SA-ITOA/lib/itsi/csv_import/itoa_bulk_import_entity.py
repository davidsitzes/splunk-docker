# Copyright (C) 2005-2018 Splunk Inc. All Rights Reserved.

from splunk.appserver.mrsparkle.lib import i18n
from itoa_bulk_import_common import (UPSERT_UPDATE_TYPE,
                                     REPLACE_UPDATE_TYPE,
                                     APPEND_UPDATE_TYPE,
                                     DEFAULT_UPDATE_TYPE,
                                     CSVLoaderError,
                                     CSVLoaderBadReq)

from collections import MutableMapping, defaultdict
from itertools import chain
from itsi.itsi_utils import ITOAInterfaceUtils
from itsi.itsi_const import ITOAObjConst
import datetime
import collections

RESERVED_WORDS = ITOAObjConst.ENTITY_INTERNAL_KEYWORDS

# try:  # noqa: F401
#     from typing import Iterable, Iterator, Sequence, Dict, List, Text, Any, Optional, Union, Callable, Tuple, Mapping  # noqa: F401
#     from itoa_bulk_import_service_cache import ServiceCache  # noqa: F401
# except:  # noqa: F401
#     pass  # noqa: F401


class EntityMetadata(MutableMapping):
    """
    A special-purpose dictionary that represents the keys and values to be added to an
    entity as either its informational or identifier objects.  The values are sets: We
    assume that for a given identifier name, we have a list of unique identifier values
    for that name.

    As this is a mapping, using dict.update() will automagically add all the keys and
    values to the receiving dictionary; for the metadata field itself, there's a
    method to produce the lists of unique fieldnames and values we're associating
    with the entity.
    """

    # The errors in this class are all 500 errors.  By the time the parser instantiates
    # this object, it MUST have verified that the object's fields are valid.  If it
    # hasn't, that's a developer error.

    def __init__(self, *args, **kwargs):
        self._data = defaultdict(set)
        self.update(dict(*args, **kwargs))

    def __getitem__(self, key):
        # type: (str) -> List[Set]
        return self._data[key]

    def __delitem__(self, key):
        # type: (str) -> None
        del self._data[key]

    def __iter__(self):
        # type: () -> Iterator
        return iter(self._data)

    def __len__(self):
        # type: () -> int
        return len(self._data)

    def __str__(self):
        # type: () -> str
        return str(self._data)

    def __setitem__(self, key, value):
        # type: (Text, Set) -> None
        if key in RESERVED_WORDS:
            raise CSVLoaderBadReq(_('Attempt to use reserved word "{}" as a fieldname.').format(key))
        if not isinstance(value, collections.Iterable):
            raise CSVLoaderError(_('Non-iterable passed as metadata value.'))
        self._data[key] = set(value)
        return None

    def union(self, other):
        # type: (EntityMetadata) -> EntityMetadata
        # Like dict.update, but creates unions of related content values
        for key in set(self.keys()).union(other.keys()):
            self[key] = self.get(key, set()).union(other.get(key, set()))
        return self

    def export_as_lists(self):
        # type: () -> Mapping[str, List[Text]]
        # Used to export the metadata back into something that can be passed
        # to storage.
        return dict([(k, list(v)) for (k, v) in self.iteritems()])

    def meta_repr(self):
        # type: () -> Dict[Text, List[Text]]
        # That list(set(list(chain... train may seem a little odd, but the innermost
        # 'list' unpacks the chain flatten iterator to flatten the list, 'set' ensures
        # unique values, and then the final 'list' converts the set back into something we
        # can pass to storage.
        return {
            'fields': sorted(self.keys()),
            'values': sorted(list(set(list(chain(*self.values())))))
        }


class ImportedEntity(object):
    """
    Represents an entity to be imported: its fields, validations, and parsing.  An entity in this format
    is assumed to be a dictionary of:
        title: Text
        description: List[Text]
        services: List[Text]
        informational: Dict[Text, List[Text]]
        identifiers: Dict[Text, List[Text]]
    ... with the caveat that none of the keys appearing in the dictionaries specified for
    the informational or identifiers fields can conflict with the ENTITY_INTERNAL_KEYWORDS
    set specified above.
    """

    def __init__(self, imported_entity, user='nobody', source='unknown'):
        # type: (Dict, Text, Text) -> None
        """
        @param imported_entity: A dictionary representation of the entity as generated by the import parser.
        @param user: The current user, used to track who's responsible for adding this entity
        @param source: The source of the current upload.
        """

        self._key = imported_entity.get('_key', '') or ITOAInterfaceUtils.generate_backend_key()
        self.description = set(imported_entity['description'])
        self.identifiers = EntityMetadata(imported_entity['identifiers'])
        self.informational = EntityMetadata(imported_entity['informational'])
        self.services = set(imported_entity['services'])
        self.title = imported_entity['title']
        self.identifying_name = self.title.lower().strip()

        current_time = str(datetime.datetime.now())

        self.create_by = user
        self.create_source = source
        self.create_time = current_time

        self.mod_by = user
        self.mod_source = source
        self.mod_time = current_time

    def to_storage_repr(self, service_cache=None):
        # type: (Optional[ServiceCache]) -> Dict[str, Any]
        """
        Returns a version of the entity suitable for sending to Storage.
        """
        object_type = 'entity'
        current_time = str(datetime.datetime.now())
        services = []
        if service_cache:
            services = [{'_key': service_cache[s]['_key'], 'title': s} for s in self.services]

        to_storage_object = {
            '_key': self._key,
            '_type': object_type,
            'create_by': self.create_by,
            'create_source': self.create_source,
            'create_time': self.create_time,
            'description': '. '.join(self.description),
            'identifier': self.identifiers.meta_repr(),
            'informational': self.informational.meta_repr(),
            'mod_by': self.mod_by,
            'mod_source': self.mod_source,
            'mod_time': current_time,
            'object_type': object_type,
            'services': services,
            'title': self.title,
            'identifying_name': self.title.strip().lower()
        }

        to_storage_object.update(self.identifiers.export_as_lists())
        to_storage_object.update(self.informational.export_as_lists())

        return to_storage_object

    def __str__(self):
        # type: () -> str
        import pprint
        return pprint.pformat(self.to_storage_repr(), indent=4)

    def update_with_imported_entity(self, other_entity):
        # type: (ImportedEntity) -> ImportedEntity
        """
        RULE: If more than one row of the import source has the same title for an entity, then
        all of the unique descriptions, identifiers, informationals, and services
        accumulate.
        """

        if (self.identifying_name != other_entity.identifying_name):
            raise CSVLoaderError(_("Attempted to merge unrelated entities: {} {}.").format(
                self.identifying_name, other_entity.identifying_name))
        self.description = self.description.union(other_entity.description)
        self.identifiers = self.identifiers.union(other_entity.identifiers)
        self.informational = self.informational.union(other_entity.informational)
        self.services = self.services.union(other_entity.services)
        return self

    def update_with_entity_from_storage(self, other_entity, strategy=DEFAULT_UPDATE_TYPE):
        # type: (StorageEntity, str) -> ImportedEntity
        """
        Update this entity with data from an entity found in storage, if any.
        @param other_entity: An entity object from storage
        @param strategy: How the two objects are to interact to perform the update
        """

        def update_by_append(from_storage):
            # type: (StorageEntity) -> None
            # RULE: (APPEND) Do nothing. Conflicting entities will be removed from the update
            # by the commit pass.
            raise CSVLoaderError(_("Merge update called when strategy is append, cannot handle."))

        def update_by_replace(from_storage):
            # type: (StorageEntity) -> None
            # RULE (REPLACE) We assume the existing entity's identity, but impose our new
            # identifiers and informationals.  We also impose our own descriptions unless
            # those are not present in the new entity, in which case we copy them from the
            # original.
            self._key = from_storage._key
            self.description = self.description or from_storage.description

        def update_by_upsert(from_storage):
            # type: (StorageEntity) -> None
            # RULE (UPSERT) We assume the existing entity's identity, and merge the union
            # of the two entities' informational, identifier, and description fields.
            self._key = from_storage._key
            # Note that this description pattern is the opposite of update_by_replace
            self.description = from_storage.description.union(self.description)
            self.identifiers = self.identifiers.union(from_storage.identifiers)
            self.informational = self.informational.union(from_storage.informational)

        update_strategies = {
            UPSERT_UPDATE_TYPE: update_by_upsert,
            REPLACE_UPDATE_TYPE: update_by_replace,
            APPEND_UPDATE_TYPE: update_by_append
        }

        update_strategies[strategy](other_entity)

        # Preserve original information
        self._key = other_entity._key
        self.create_by = other_entity.create_by
        self.create_source = other_entity.create_source
        self.create_time = other_entity.create_time

        return self


class StorageEntity(object):
    """
    Represents an entity as retrieved from Storage.  This is primarily a nice conversion
    layer that makes ImportedEntity.update_with_entity_from_storage far more readable.
    """
    def __init__(self, storage_entity):
        # type: (Dict[Text, Any]) -> None
        """
        Unpack a storage_entity into a type that can be used for replace/upsert in the ImportedEntity
        @param storage_entity: An entity object as retrieved from the backend.
        """
        self._key = storage_entity['_key']
        self.description = set([storage_entity.get('description', '')])
        self.services = storage_entity.get('services', [])
        self.title = storage_entity['title']
        self.identifiers = StorageEntity._unpack_metadata('identifier', storage_entity)
        self.informational = StorageEntity._unpack_metadata('informational', storage_entity)

        self.create_by = storage_entity.get('create_by', 'unknown')
        self.create_source = storage_entity.get('create_source', '')
        self.create_time = storage_entity.get('create_time', '')

        self.mod_by = storage_entity.get('mod_by', 'unknown')
        self.mod_source = storage_entity.get('mod_source', '')
        self.mod_time = storage_entity.get('mod_time', '')

    @staticmethod
    def _unpack_metadata(metatype, storage_entity):
        # type: (Text, Dict[Text, Any]) -> EntityMetadata
        # Convert a KV-stored entity's informational and identifier fields into mutable
        # dictionaries that properly track the value types.
        # @param metatype: "informational" or "identifier"
        # @param storage_entity: An entity dictionary as derived from KVStore

        metadata = storage_entity.get(metatype, {'fields': [], 'values': []})
        return EntityMetadata([(field, set(storage_entity.get(field, []))) for field in metadata['fields']])
